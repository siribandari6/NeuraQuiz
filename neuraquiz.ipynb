{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ***üß†NeuraQuiz: Neural-Powered Quiz Engine to generate, explain, and evaluate educational content.***","metadata":{}},{"cell_type":"markdown","source":"# Installing all the required Dependenices!!!!","metadata":{}},{"cell_type":"code","source":"# Install dependencies\n!pip install -q PyPDF2 google-generativeai openai\n!pip install -q git+https://github.com/openai/whisper.git --no-deps\n!pip install -q --upgrade google-generativeai\n!pip install -q streamlit pyngrok\n!pip install -q streamlit pyngrok ffmpeg-python\n\n# Imports\nimport os\nimport google.generativeai as genai\nimport whisper\nfrom PyPDF2 import PdfReader\nfrom PIL import Image\nimport io\nfrom IPython.display import display, Markdown\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Configure Gemini API with Kaggle Secrets:","metadata":{}},{"cell_type":"code","source":"# Use Kaggle secrets for Gemini API\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nGOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")  # Store in \"Add a new secret\"\n\ngenai.configure(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generate MCQs from PDFs:","metadata":{}},{"cell_type":"code","source":"def extract_text_from_pdf(file_path):\n    reader = PdfReader(file_path)\n    return \" \".join([page.extract_text() for page in reader.pages])\n\ndef generate_mcqs_from_text(text):\n    model = genai.GenerativeModel(\"models/gemini-1.5-pro-latest\")\n    prompt = (\n        \"You are an AI quiz generator. Based on the content below, generate exactly 5 MCQs.\\n\"\n        \"Return your output in this strict JSON format only:\\n\"\n        \"[\\n\"\n        \"  {\\n\"\n        \"    \\\"question\\\": \\\"...\\\",\\n\"\n        \"    \\\"options\\\": [\\\"A\\\", \\\"B\\\", \\\"C\\\", \\\"D\\\"],\\n\"\n        \"    \\\"answer\\\": \\\"B\\\",\\n\"\n        \"    \\\"explanation\\\": \\\"...\\\"\\n\"\n        \"  },\\n\"\n        \"  ...\\n\"\n        \"]\\n\"\n        \"Do NOT include any markdown, numbers, or additional comments.\\n\\n\"\n        f\"Content:\\n{text[:3000]}\"\n    )\n    return model.generate_content(prompt).text\n\n\n# ‚úÖ Helper: Cleanly display MCQs (Kaggle Cell 6)\ndef display_mcqs(mcqs_raw):\n    try:\n        try:\n            mcqs_data = json.loads(mcqs_raw)\n        except json.JSONDecodeError:\n            mcqs_data = eval(mcqs_raw, {\"__builtins__\": {}})\n\n        if isinstance(mcqs_data, list):\n            questions = mcqs_data\n        elif isinstance(mcqs_data, dict) and \"quiz\" in mcqs_data:\n            questions = mcqs_data[\"quiz\"]\n        else:\n            display(Markdown(\"‚ö†Ô∏è **Unrecognized format:**\"))\n            display(Markdown(f\"```\\n{mcqs_raw}\\n```\"))\n            return\n\n        for i, q in enumerate(questions):\n            display(Markdown(f\"### Q{i+1}: {q.get('question', 'N/A')}\"))\n            for opt in q.get(\"options\", []):\n                display(Markdown(f\"- {opt}\"))\n            display(Markdown(f\"‚úÖ **Answer:** {q.get('answer', 'N/A')}\"))\n            display(Markdown(f\"üí° _Explanation_: {q.get('explanation', 'N/A')}\"))\n            display(Markdown(\"---\"))\n\n    except Exception as e:\n        display(Markdown(f\"‚ùå **Error parsing MCQs:** {e}\"))\n        display(Markdown(f\"```\\n{mcqs_raw}\\n```\"))\n\n\n# Upload PDF\nimport ipywidgets as widgets\nfrom IPython.display import display\n\n# ‚úÖ Upload widget and handler\nuploader = widgets.FileUpload(accept='.pdf', multiple=False)\n# display(Markdown(\"### üìÑ Upload a PDF to generate MCQs\"))\ndisplay(uploader)\n\ndef handle_pdf_upload(change):\n    for name, file_info in uploader.value.items():\n        with open(name, 'wb') as f:\n            f.write(file_info['content'])\n        text = extract_text_from_pdf(name)\n        print(\"‚úÖ Extracted text. Generating MCQs...\")\n        mcqs = generate_mcqs_from_text(text)\n        display_mcqs(mcqs)\n\nuploader.observe(handle_pdf_upload, names='value')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Generate MCQs from an Image:","metadata":{}},{"cell_type":"code","source":"def generate_mcqs_from_image(image):\n    model = genai.GenerativeModel(\"models/gemini-1.5-pro-latest\")\n    prompt = (\n        \"You are an AI quiz generator. Based on this educational image, generate exactly 3 MCQs.\\n\"\n        \"Return your output in this strict JSON format only:\\n\"\n        \"[\\n\"\n        \"  {\\n\"\n        \"    \\\"question\\\": \\\"...\\\",\\n\"\n        \"    \\\"options\\\": [\\\"A\\\", \\\"B\\\", \\\"C\\\", \\\"D\\\"],\\n\"\n        \"    \\\"answer\\\": \\\"B\\\",\\n\"\n        \"    \\\"explanation\\\": \\\"...\\\"\\n\"\n        \"  },\\n\"\n        \"  ...\\n\"\n        \"]\\n\"\n        \"Do NOT include markdown or formatting ‚Äî only return JSON.\"\n    )\n    return model.generate_content([prompt, image]).text\n\n\n# -- MCQ DISPLAY FUNCTION --\ndef display_mcqs(mcqs_raw):\n    try:\n        try:\n            mcqs_data = json.loads(mcqs_raw)\n        except json.JSONDecodeError:\n            mcqs_data = eval(mcqs_raw, {\"__builtins__\": {}})\n\n        if isinstance(mcqs_data, list):\n            questions = mcqs_data\n        elif isinstance(mcqs_data, dict) and \"quiz\" in mcqs_data:\n            questions = mcqs_data[\"quiz\"]\n        else:\n            display(Markdown(\"‚ö†Ô∏è **Unrecognized format. Showing raw output:**\"))\n            display(Markdown(f\"```\\n{mcqs_raw}\\n```\"))\n            return\n\n        for i, q in enumerate(questions):\n            display(Markdown(f\"### Q{i+1}: {q.get('question', 'N/A')}\"))\n            for opt in q.get(\"options\", []):\n                display(Markdown(f\"- {opt}\"))\n            display(Markdown(f\"‚úÖ **Answer:** {q.get('answer', 'N/A')}\"))\n            display(Markdown(f\"üí° _Explanation_: {q.get('explanation', 'N/A')}\"))\n            display(Markdown(\"---\"))\n\n    except Exception as e:\n        display(Markdown(f\"‚ùå **Error parsing MCQs:** {e}\"))\n        display(Markdown(f\"```\\n{mcqs_raw}\\n```\"))\n\n# -- IMAGE UPLOAD WIDGET --\nimg_uploader = widgets.FileUpload(accept='image/*', multiple=False)\ndisplay(Markdown(\"### üñºÔ∏è Upload an image to generate quiz questions\"))\ndisplay(img_uploader)\n\ndef handle_img_upload(change):\n    for name, file_info in img_uploader.value.items():\n        if file_info[\"metadata\"][\"type\"].startswith(\"image/\"):\n            display(Markdown(f\"üìÑ **Processing**: {name}\"))\n            mcqs = generate_mcqs_from_image(file_info['content'])\n            display_mcqs(mcqs)\n        else:\n            display(Markdown(\"‚ùå Uploaded file is not a supported image.\"))\n\nimg_uploader.observe(handle_img_upload, names='value')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Transcribe and Summarize Video Lectures:","metadata":{}},{"cell_type":"code","source":"whisper_model = whisper.load_model(\"base\")\n\ndef transcribe_and_summarize(file_path):\n    transcript = whisper_model.transcribe(file_path)[\"text\"]\n    print(\"üìú Transcript extracted. Generating summary...\")\n\n    model = genai.GenerativeModel(\"models/gemini-1.5-pro-latest\")\n    response = model.generate_content(f\"Summarize the following lecture in bullet points:\\n{transcript[:3000]}\")\n    return response.text\n\nvideo_uploader = widgets.FileUpload(accept='.mp4', multiple=False)\ndisplay(video_uploader)\n\ndef handle_video_upload(change):\n    for name, file_info in video_uploader.value.items():\n        with open(name, 'wb') as f:\n            f.write(file_info['content'])\n        summary = transcribe_and_summarize(name)\n        display(Markdown(f\"### üé• Lecture Summary:\\n{summary}\"))\n\nvideo_uploader.observe(handle_video_upload, names='value')\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluate Student Answers with Gemini:","metadata":{}},{"cell_type":"code","source":"from IPython.display import display, Markdown\n\ndef evaluate_answer(student_ans, ideal_q, ideal_ans):\n    prompt = f\"\"\"\n    Evaluate the student's answer:\n    Question: {ideal_q}\n    Ideal Answer: {ideal_ans}\n    Student's Answer: {student_ans}\n    Give score out of 10 and feedback.\n    \"\"\"\n    model = genai.GenerativeModel(\"models/gemini-1.5-pro-latest\")\n    response = model.generate_content(prompt)\n    return response.text\n\n# Example usage\nstudent = \"Photosynthesis happens in mitochondria.\"\nideal_q = \"Where does photosynthesis occur in plant cells?\"\nideal_ans = \"In the chloroplasts.\"\n\nfeedback = evaluate_answer(student, ideal_q, ideal_ans)\ndisplay(Markdown(f\"### üß™ Evaluation:\\n{feedback}\"))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Streamlit UI Code:","metadata":{}},{"cell_type":"code","source":"streamlit_code = '''\nimport streamlit as st\nimport google.generativeai as genai\nimport whisper\nfrom PyPDF2 import PdfReader\nfrom PIL import Image\nimport tempfile\nimport os\nimport json\nfrom kaggle_secrets import UserSecretsClient\n\n# Load API Key\nuser_secrets = UserSecretsClient()\nGOOGLE_API_KEY = user_secrets.get_secret(\"GOOGLE_API_KEY\")\ngenai.configure(api_key=GOOGLE_API_KEY)\n\n# Load Whisper model\nwhisper_model = whisper.load_model(\"base\")\n\n# Extract text from PDF\ndef extract_text_from_pdf(file):\n    reader = PdfReader(file)\n    return \" \".join([page.extract_text() for page in reader.pages])\n\n# Generate MCQs from PDF text\ndef generate_mcqs_from_text(text):\n    model = genai.GenerativeModel(\"models/gemini-1.5-pro-latest\")\n    prompt = (\n        \"Generate 5 MCQs in JSON format like:\\\\n\"\n        \"[{\\\\\"question\\\\\": \\\\\"...\\\\\", \\\\\"options\\\\\": [...], \\\\\"answer\\\\\": \\\\\"...\\\\\", \\\\\"explanation\\\\\": \\\\\"...\\\\\"}]\\\\n\"\n        f\"Text:\\\\n{text[:3000]}\"\n    )\n    return model.generate_content(prompt).text\n\n# Generate MCQs from image\ndef generate_mcqs_from_image(image):\n    model = genai.GenerativeModel(\"models/gemini-1.5-pro-latest\")\n    prompt = (\n        \"Analyze this educational image and generate 3 MCQs in strict JSON format like:\\\\n\"\n        \"[{\\\\\"question\\\\\": \\\\\"...\\\\\", \\\\\"options\\\\\": [...], \\\\\"answer\\\\\": \\\\\"...\\\\\", \\\\\"explanation\\\\\": \\\\\"...\\\\\"}]\\\\n\"\n        \"Do not use markdown, numbering, or commentary. Only return valid JSON.\"\n    )\n    return model.generate_content([prompt, image]).text\n\n# Transcribe and summarize video\ndef transcribe_and_summarize(video_path):\n    result = whisper_model.transcribe(video_path)\n    transcript = result['text']\n    model = genai.GenerativeModel(\"models/gemini-1.5-pro-latest\")\n    prompt = f\"Summarize the following lecture in bullet points:\\\\n{transcript[:3000]}\"\n    return model.generate_content(prompt).text\n\n# Evaluate student answer\ndef evaluate_student_answer(question, ideal, student):\n    model = genai.GenerativeModel(\"models/gemini-1.5-pro-latest\")\n    prompt = f\"Q: {question}\\\\nIdeal: {ideal}\\\\nStudent: {student}\\\\nGive score out of 10 and feedback.\"\n    return model.generate_content(prompt).text\n\n# Recommend learning path\ndef recommend_learning_path(level, goal):\n    model = genai.GenerativeModel(\"models/gemini-1.5-pro-latest\")\n    prompt = f\"I am a {level} student. My goal is to {goal}. Suggest a 2-week learning path.\"\n    return model.generate_content(prompt).text\n    \ndef render_quiz_ui(quiz_raw):\n    import re\n\n    st.markdown(\"## üìò NeuraQuiz Results\")\n    try:\n        # Step 1: Remove markdown fences like ```json\n        cleaned = re.sub(r\"```[a-zA-Z]*\", \"\", quiz_raw).strip(\\\"` \\\\n\\\")\n\n        # Step 2: Try parsing JSON\n        try:\n            quiz_data = json.loads(cleaned)\n        except json.JSONDecodeError:\n            # Fallback to eval\n            quiz_data = eval(cleaned, {\"__builtins__\": {}})\n\n        # Step 3: Extract questions\n        if isinstance(quiz_data, dict) and \"quiz\" in quiz_data:\n            questions = quiz_data[\"quiz\"]\n        elif isinstance(quiz_data, list):\n            questions = quiz_data\n        else:\n            st.error(\"‚ö†Ô∏è Output is not a valid quiz format.\")\n            st.code(cleaned)\n            return\n\n        # Step 4: Render quiz\n        for i, q in enumerate(questions):\n            st.markdown(f\"### Q{i+1}: {q.get('question', 'N/A')}\")\n            st.markdown(\"**Options**\")\n            labels = [\"A\", \"B\", \"C\", \"D\"]\n            for idx, opt in enumerate(q.get(\"options\", [])):\n                label = labels[idx] if idx < len(labels) else f\"Option {idx+1}\"\n                st.markdown(f\"**{label})** {opt}\")\n            st.markdown(f\"‚úÖ **Answer:** {q.get('answer', 'N/A')}\")\n            st.markdown(f\"üí° *Explanation*: {q.get('explanation', 'N/A')}\")\n            st.markdown(\"---\")\n\n    except Exception as e:\n        st.error(f\"‚ùå Error parsing quiz: {e}\")\n        st.code(quiz_raw)\n\n\n\n# --- Streamlit App UI ---\nst.set_page_config(page_title=\"NeuraQuiz\", layout=\"centered\")\nst.markdown(\"# üß† NeuraQuiz\")\nst.markdown(\"##### Neural-Powered Quiz Engine to generate, explain, and evaluate educational content.\")\n\noption = st.sidebar.radio(\"Select Feature\", [\n    \"üìÑ PDF to Quiz\", \"üñºÔ∏è Image to Quiz\", \"üé• Video Summary\", \"üß™ Answer Evaluation\", \"üéØ Learning Path\"\n])\n\nif option == \"üìÑ PDF to Quiz\":\n    file = st.file_uploader(\"Upload a PDF\", type=[\"pdf\"])\n    if file and st.button(\"Generate Quiz\"):\n        text = extract_text_from_pdf(file)\n        quiz = generate_mcqs_from_text(text)\n        render_quiz_ui(quiz)\n\nelif option == \"üñºÔ∏è Image to Quiz\":\n    file = st.file_uploader(\"Upload an image\", type=[\"jpg\", \"jpeg\", \"png\"])\n    if file and st.button(\"Generate Quiz\"):\n        img = Image.open(file)\n        quiz = generate_mcqs_from_image(img)\n        render_quiz_ui(quiz)\n\nelif option == \"üé• Video Summary\":\n    file = st.file_uploader(\"Upload a video (mp4)\", type=[\"mp4\"])\n    if file and st.button(\"Transcribe & Summarize\"):\n        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\") as tmp:\n            tmp.write(file.read())\n            summary = transcribe_and_summarize(tmp.name)\n        st.markdown(summary)\n\nelif option == \"üß™ Answer Evaluation\":\n    q = st.text_area(\"Question\")\n    ideal = st.text_area(\"Ideal Answer\")\n    student = st.text_area(\"Student Answer\")\n    if st.button(\"Evaluate\"):\n        feedback = evaluate_student_answer(q, ideal, student)\n        st.markdown(f\"### üß™ Feedback:\\\\n{feedback}\")\n\nelif option == \"üéØ Learning Path\":\n    level = st.selectbox(\"Student Level\", [\"Beginner\", \"Intermediate\", \"Advanced\"])\n    goal = st.text_input(\"Goal (e.g., learn calculus)\")\n    if st.button(\"Get Recommendation\"):\n        path = recommend_learning_path(level, goal)\n        st.markdown(path)\n'''\nwith open(\"streamlit_app.py\", \"w\") as f:\n    f.write(streamlit_code)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Running NeuraQuiz Streamlit App in Kaggle by using ngrok:","metadata":{}},{"cell_type":"code","source":"!ngrok config add-authtoken <YOUR TOKEN>","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import subprocess\nfrom pyngrok import ngrok\n\nport = 6006\npublic_url = ngrok.connect(port)\nprint(\"üîó Your Streamlit App URL:\", public_url)\n\n# Start Streamlit with access to secrets\nprocess = subprocess.Popen([\"streamlit\", \"run\", \"streamlit_app.py\", \"--server.port\", str(port)])\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}